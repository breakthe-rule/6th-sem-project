{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/breakthe-rule/6th-sem-project/blob/main/code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuNSfzSP_1gz",
        "outputId": "efbafa7e-0cfa-468f-dd89-5d1bf971fc39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.6), please consider upgrading to the latest version (0.3.7).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/bmadushanirodrigo/x-ray-and-non-x-ray-image-classification-data?dataset_version_number=2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 99.7M/99.7M [00:00<00:00, 119MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset downloaded and moved to: /content/x-ray-and-non-x-ray-image-classification-data/\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "import shutil\n",
        "\n",
        "# Download the dataset to the default cache location\n",
        "path = kagglehub.dataset_download(\"bmadushanirodrigo/x-ray-and-non-x-ray-image-classification-data\")\n",
        "\n",
        "# Define the target path within /content directory\n",
        "target_path = '/content/x-ray-and-non-x-ray-image-classification-data/'\n",
        "\n",
        "# Move the dataset to the /content directory\n",
        "shutil.move(path, target_path)\n",
        "\n",
        "print(\"Dataset downloaded and moved to:\", target_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import os"
      ],
      "metadata": {
        "id": "xnPV8aZRGiuF"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# 1. Dataset & DataLoader Setup\n",
        "# ============================\n",
        "\n",
        "# Define dataset root directory\n",
        "dataset_root = \"/content/x-ray-and-non-x-ray-image-classification-data/Xray_Classifier/Xray_Classifier\"\n",
        "\n",
        "# Paths for train, validation, and test sets\n",
        "train_dir = os.path.join(dataset_root, \"train\")\n",
        "val_dir = os.path.join(dataset_root, \"val\")\n",
        "test_dir = os.path.join(dataset_root, \"test\")\n",
        "\n",
        "# Image transformations\n",
        "image_transforms = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),  # Resize images\n",
        "    transforms.ToTensor(),  # Convert to tensor\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize\n",
        "])\n",
        "\n",
        "# Load datasets\n",
        "train_dataset = datasets.ImageFolder(root=train_dir, transform=image_transforms)\n",
        "val_dataset = datasets.ImageFolder(root=val_dir, transform=image_transforms)\n",
        "test_dataset = datasets.ImageFolder(root=test_dir, transform=image_transforms)\n",
        "\n",
        "# Define batch size\n",
        "batch_size = 32\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "# Print class mapping\n",
        "print(\"Class Mapping:\", train_dataset.class_to_idx)  # {'non_xray': 0, 'xray': 1}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUzSBYOXKL5j",
        "outputId": "cad02710-cd60-4aac-f353-53c1c3dc3854"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Mapping: {'non_xray': 0, 'xray': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CustomCNN(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super().__init__()\n",
        "\n",
        "        # Convolutional layers with batch normalization\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "\n",
        "        # Global Average Pooling\n",
        "        self.gap = nn.AdaptiveAvgPool2d(1)  # Output size (1,1)\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(128, 256)\n",
        "        self.fc2 = nn.Linear(256, num_classes)\n",
        "\n",
        "        # Define masks for keeping specific neurons inactive\n",
        "        self.mask_conv1 = torch.ones_like(self.conv1.weight)\n",
        "        self.mask_conv1[5:15] = 0  # Fix neurons 5-9 inactive\n",
        "\n",
        "        self.mask_conv2 = torch.ones_like(self.conv2.weight)\n",
        "        self.mask_conv2[10:30] = 0  # Fix neurons 10-19 inactive\n",
        "\n",
        "        self.mask_conv3 = torch.ones_like(self.conv3.weight)\n",
        "        self.mask_conv3[20:60] = 0  # Fix neurons 20-39 inactive\n",
        "\n",
        "        self.mask_fc1 = torch.ones_like(self.fc1.weight)\n",
        "        self.mask_fc1[40:100] = 0  # Fix neurons 50-99 inactive\n",
        "\n",
        "        self.mask_fc2 = torch.ones_like(self.fc2.weight)\n",
        "        self.mask_fc2[10:100] = 0  # Fix neurons 10-49 inactive\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "\n",
        "        x = self.gap(x)  # Global Average Pooling\n",
        "        x = torch.flatten(x, start_dim=1)  # Shape: (batch_size, 128)\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def zero_grad_neurons(self):\n",
        "        \"\"\"Ensures specific neurons never update and remain zero\"\"\"\n",
        "        device = self.conv1.weight.device  # Get current device\n",
        "        self.mask_conv1 = self.mask_conv1.to(device)\n",
        "        self.mask_conv2 = self.mask_conv2.to(device)\n",
        "        self.mask_conv3 = self.mask_conv3.to(device)\n",
        "        self.mask_fc1 = self.mask_fc1.to(device)\n",
        "        self.mask_fc2 = self.mask_fc2.to(device)\n",
        "\n",
        "        # Zero out gradients for selected neurons\n",
        "        if self.conv1.weight.grad is not None:\n",
        "            self.conv1.weight.grad *= self.mask_conv1\n",
        "        if self.conv2.weight.grad is not None:\n",
        "            self.conv2.weight.grad *= self.mask_conv2\n",
        "        if self.conv3.weight.grad is not None:\n",
        "            self.conv3.weight.grad *= self.mask_conv3\n",
        "        if self.fc1.weight.grad is not None:\n",
        "            self.fc1.weight.grad *= self.mask_fc1\n",
        "        if self.fc2.weight.grad is not None:\n",
        "            self.fc2.weight.grad *= self.mask_fc2\n",
        "\n",
        "        # Force weights to remain zero for masked neurons\n",
        "        with torch.no_grad():\n",
        "            self.conv1.weight *= self.mask_conv1\n",
        "            self.conv2.weight *= self.mask_conv2\n",
        "            self.conv3.weight *= self.mask_conv3\n",
        "            self.fc1.weight *= self.mask_fc1\n",
        "            self.fc2.weight *= self.mask_fc2\n"
      ],
      "metadata": {
        "id": "1kLKgKOAKROZ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# 3. Training, Validation, and Testing\n",
        "# ============================\n",
        "from time import time\n",
        "\n",
        "def train_model(model, train_loader, val_loader, num_epochs=10, lr=0.001):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    print(f'Device: {device}')\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()  # For multi-class classification\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch: {epoch}/{num_epochs}')\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct, total = 0, 0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            model.zero_grad_neurons()  # Zero out specific gradients\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        train_acc = 100 * correct / total\n",
        "        val_loss, val_acc = validate_model(model, val_loader, criterion, device)\n",
        "\n",
        "        print(f\"Train Loss: {running_loss/len(train_loader):.4f}, Train Acc: {train_acc:.2f}% | \"\n",
        "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
        "\n",
        "def validate_model(model, val_loader, criterion, device):\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct, total = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    val_acc = 100 * correct / total\n",
        "    return val_loss / len(val_loader), val_acc\n",
        "\n",
        "def test_model(model, test_loader):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    test_acc = 100 * correct / total\n",
        "    print(f\"Test Accuracy: {test_acc:.2f}%\")\n"
      ],
      "metadata": {
        "id": "9Jf_RZJKKWcv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# 4. Run Training & Testing\n",
        "# ============================\n",
        "\n",
        "# Initialize model\n",
        "model = CustomCNN(num_classes=2)\n",
        "\n",
        "# Train model\n",
        "train_model(model, train_loader, val_loader, num_epochs=10, lr=0.001)\n",
        "\n",
        "# Test model\n",
        "test_model(model, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "8BzjTA5iKZTE",
        "outputId": "74e2b317-277d-48ee-ec89-147953012d0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "Epoch: 0/10\n",
            "Train Loss: 0.2065, Train Acc: 94.26% | Val Loss: 0.1958, Val Acc: 99.58%\n",
            "Epoch: 1/10\n",
            "Train Loss: 0.0602, Train Acc: 98.23% | Val Loss: 0.0413, Val Acc: 98.14%\n",
            "Epoch: 2/10\n",
            "Train Loss: 0.0266, Train Acc: 99.16% | Val Loss: 0.0202, Val Acc: 99.92%\n",
            "Epoch: 3/10\n",
            "Train Loss: 0.0181, Train Acc: 99.66% | Val Loss: 0.1336, Val Acc: 99.49%\n",
            "Epoch: 4/10\n",
            "Train Loss: 0.2121, Train Acc: 96.96% | Val Loss: 0.2465, Val Acc: 96.54%\n",
            "Epoch: 5/10\n",
            "Train Loss: 0.2070, Train Acc: 95.61% | Val Loss: 0.0590, Val Acc: 98.40%\n",
            "Epoch: 6/10\n",
            "Train Loss: 0.0761, Train Acc: 97.55% | Val Loss: 0.0411, Val Acc: 99.16%\n",
            "Epoch: 7/10\n",
            "Train Loss: 0.0363, Train Acc: 99.16% | Val Loss: 0.0217, Val Acc: 99.41%\n",
            "Epoch: 8/10\n",
            "Train Loss: 0.0217, Train Acc: 99.24% | Val Loss: 0.0134, Val Acc: 99.58%\n",
            "Epoch: 9/10\n",
            "Train Loss: 0.0130, Train Acc: 99.75% | Val Loss: 0.0123, Val Acc: 99.58%\n",
            "Test Accuracy: 99.64%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "import shutil\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"hemanthsai7/solar-panel-dust-detection\")\n",
        "\n",
        "# Define the target path within /content directory\n",
        "target_path = '/content/solar-panel-dust-detection/'\n",
        "\n",
        "# Move the dataset to the /content directory\n",
        "shutil.move(path, target_path)\n",
        "\n",
        "print(\"Dataset downloaded and moved to:\", target_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "Nj5ex9ROWMws",
        "outputId": "3c83eedc-61bf-46bd-c02b-e3b2bb232b93"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-290dab29d26d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Download latest version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkagglehub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"hemanthsai7/solar-panel-dust-detection\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Define the target path within /content directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/kagglehub/datasets.py\u001b[0m in \u001b[0;36mdataset_download\u001b[0;34m(handle, path, force_download)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_dataset_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Downloading Dataset: {h.to_url()} ...\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mEXTRA_CONSOLE_BLOCK\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_resolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_download\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_download\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/kagglehub/registry.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mimpl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mimpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_supported\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0mfails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/kagglehub/http_resolver.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, h, path, force_download)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDatasetHandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_download\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mapi_client\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKaggleApiV1Client\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_versioned\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/kagglehub/clients.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcredentials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_kaggle_credentials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_kaggle_api_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/kagglehub/config.py\u001b[0m in \u001b[0;36mget_kaggle_credentials\u001b[0;34m()\u001b[0m\n\u001b[1;32m     98\u001b[0m                 \u001b[0musername\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreds_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCREDENTIALS_JSON_USERNAME\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreds_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCREDENTIALS_JSON_KEY\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             )\n\u001b[0;32m--> 100\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mis_in_colab_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcolab_secret\u001b[0m \u001b[0;34m:=\u001b[0m \u001b[0mget_colab_credentials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mKaggleApiCredentials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musername\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolab_secret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musername\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolab_secret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/kagglehub/config.py\u001b[0m in \u001b[0;36mget_colab_credentials\u001b[0;34m()\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0musername\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_normalize_whitespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muserdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCOLAB_SECRET_USERNAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_normalize_whitespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muserdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCOLAB_SECRET_KEY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0musername\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/userdata.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m     60\u001b[0m   \u001b[0;31m# thread-safe.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0m_userdata_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     resp = _message.blocking_request(\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0;34m'GetSecret'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'key'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "\n",
        "# Image transformations (matching the previous implementation)\n",
        "image_transforms = transforms.Compose([\n",
        "    transforms.Resize(128),\n",
        "    transforms.CenterCrop(128),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "])\n",
        "\n",
        "# Load full MNIST dataset\n",
        "full_dataset = datasets.MNIST(root=\"./data\", train=True, transform=image_transforms, download=True)\n",
        "\n",
        "# Filter indices: Keep only classes 0 and 1\n",
        "filtered_indices = [idx for idx, (_, label) in enumerate(full_dataset) if label in [0, 1]]\n",
        "\n",
        "# Create a new dataset with only images of \"0\" and \"1\"\n",
        "filtered_dataset = Subset(full_dataset, filtered_indices)\n",
        "\n",
        "# Separate indices for \"0\" and \"1\"\n",
        "class_indices = {0: [], 1: []}\n",
        "\n",
        "for idx in filtered_indices:\n",
        "    _, label = full_dataset[idx]\n",
        "    if len(class_indices[label]) < 1000:\n",
        "        class_indices[label].append(idx)\n",
        "    if all(len(indices) >= 1000 for indices in class_indices.values()):\n",
        "        break\n",
        "\n",
        "train_indices = class_indices[0] + class_indices[1]\n",
        "\n",
        "# Remaining indices for validation and testing\n",
        "remaining_class_indices = {0: [], 1: []}\n",
        "\n",
        "for idx in set(filtered_indices) - set(train_indices):\n",
        "    _, label = full_dataset[idx]\n",
        "    remaining_class_indices[label].append(idx)\n",
        "\n",
        "val_indices = []\n",
        "test_indices = []\n",
        "\n",
        "for label in [0, 1]:\n",
        "    random.shuffle(remaining_class_indices[label])\n",
        "    val_indices.extend(remaining_class_indices[label][:200])  # 20 per class for validation\n",
        "    test_indices.extend(remaining_class_indices[label][200:400])  # 20 per class for testing\n",
        "\n",
        "# Create subsets\n",
        "train_dataset = Subset(full_dataset, train_indices)\n",
        "val_dataset = Subset(full_dataset, val_indices)\n",
        "test_dataset = Subset(full_dataset, test_indices)\n",
        "\n",
        "# Define batch size\n",
        "batch_size = 32\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "# Print dataset sizes\n",
        "print(f\"Train dataset size: {len(train_dataset)}\")\n",
        "print(f\"Validation dataset size: {len(val_dataset)}\")\n",
        "print(f\"Test dataset size: {len(test_dataset)}\")\n",
        "\n",
        "# Print label counts to verify\n",
        "print(\"Training Labels:\", [full_dataset[i][1] for i in train_indices][:10])\n",
        "print(\"Validation Labels:\", [full_dataset[i][1] for i in val_indices][:10])\n",
        "print(\"Test Labels:\", [full_dataset[i][1] for i in test_indices][:10])\n"
      ],
      "metadata": {
        "id": "J8JIWZB-VCrw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5dee458-ed58-4fc8-e7d0-656267154815"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset size: 2000\n",
            "Validation dataset size: 400\n",
            "Test dataset size: 400\n",
            "Training Labels: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Validation Labels: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Test Labels: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ComplementaryCNN(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super().__init__()\n",
        "\n",
        "        # Convolutional layers with batch normalization\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)  # 1 input channel for MNIST\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "\n",
        "        # Global Average Pooling\n",
        "        self.gap = nn.AdaptiveAvgPool2d(1)  # Output size (1,1)\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(128, 256)\n",
        "        self.fc2 = nn.Linear(256, num_classes)\n",
        "\n",
        "        # Define masks (initialized but not moved to device yet)\n",
        "        self.mask_conv1 = torch.zeros_like(self.conv1.weight)\n",
        "        self.mask_conv1[:20] = 1  # Train first 20 filters\n",
        "\n",
        "        self.mask_conv2 = torch.zeros_like(self.conv2.weight)\n",
        "        self.mask_conv2[:40] = 1  # Train first 40 filters\n",
        "\n",
        "        self.mask_conv3 = torch.zeros_like(self.conv3.weight)\n",
        "        self.mask_conv3[:80] = 1  # Train first 80 filters\n",
        "\n",
        "        self.mask_fc1 = torch.zeros_like(self.fc1.weight)\n",
        "        self.mask_fc1[:60] = 1  # Train first 60 neurons\n",
        "\n",
        "        self.mask_fc2 = torch.zeros_like(self.fc2.weight)\n",
        "        self.mask_fc2[:90] = 1  # Train first 90 neurons\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "\n",
        "        x = self.gap(x)  # Global Average Pooling\n",
        "        x = torch.flatten(x, start_dim=1)  # Shape: (batch_size, 128)\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def zero_grad_neurons(self):\n",
        "        \"\"\"Ensures only specific neurons are trained and others remain zero\"\"\"\n",
        "        device = next(self.parameters()).device  # Get model device\n",
        "\n",
        "        # Move masks to the correct device before applying them\n",
        "        self.mask_conv1 = self.mask_conv1.to(device)\n",
        "        self.mask_conv2 = self.mask_conv2.to(device)\n",
        "        self.mask_conv3 = self.mask_conv3.to(device)\n",
        "        self.mask_fc1 = self.mask_fc1.to(device)\n",
        "        self.mask_fc2 = self.mask_fc2.to(device)\n",
        "\n",
        "        # Zero out gradients for unselected neurons\n",
        "        if self.conv1.weight.grad is not None:\n",
        "            self.conv1.weight.grad *= self.mask_conv1\n",
        "        if self.conv2.weight.grad is not None:\n",
        "            self.conv2.weight.grad *= self.mask_conv2\n",
        "        if self.conv3.weight.grad is not None:\n",
        "            self.conv3.weight.grad *= self.mask_conv3\n",
        "        if self.fc1.weight.grad is not None:\n",
        "            self.fc1.weight.grad *= self.mask_fc1\n",
        "        if self.fc2.weight.grad is not None:\n",
        "            self.fc2.weight.grad *= self.mask_fc2\n",
        "\n",
        "        # Force weights of unselected neurons to remain zero\n",
        "        with torch.no_grad():\n",
        "            self.conv1.weight *= self.mask_conv1\n",
        "            self.conv2.weight *= self.mask_conv2\n",
        "            self.conv3.weight *= self.mask_conv3\n",
        "            self.fc1.weight *= self.mask_fc1\n",
        "            self.fc2.weight *= self.mask_fc2\n",
        "\n",
        "# Initialize Model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = ComplementaryCNN(num_classes=2).to(device)  # Move model to GPU\n"
      ],
      "metadata": {
        "id": "h7NITSDwrLuy"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# 4. Run Training & Testing\n",
        "# ============================\n",
        "\n",
        "import warnings\n",
        "import os\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Initialize model\n",
        "# model = CustomCNN(num_classes=2)\n",
        "# model = ComplementaryCNN(num_classes=2)\n",
        "\n",
        "# Train model\n",
        "train_model(model, train_loader, val_loader, num_epochs=100, lr=0.00001)\n",
        "\n",
        "# Test model\n",
        "test_model(model, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pzv1W7lZxP0e",
        "outputId": "31d18b84-9581-4778-ad64-11ade96519cd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "Epoch: 0/100\n",
            "Train Loss: 0.6934, Train Acc: 52.30% | Val Loss: 0.6873, Val Acc: 96.75%\n",
            "Epoch: 1/100\n",
            "Train Loss: 0.6804, Train Acc: 94.75% | Val Loss: 0.6717, Val Acc: 95.00%\n",
            "Epoch: 2/100\n",
            "Train Loss: 0.6684, Train Acc: 94.55% | Val Loss: 0.6618, Val Acc: 95.00%\n",
            "Epoch: 3/100\n",
            "Train Loss: 0.6601, Train Acc: 93.75% | Val Loss: 0.6556, Val Acc: 94.75%\n",
            "Epoch: 4/100\n",
            "Train Loss: 0.6538, Train Acc: 93.85% | Val Loss: 0.6481, Val Acc: 95.00%\n",
            "Epoch: 5/100\n",
            "Train Loss: 0.6471, Train Acc: 93.75% | Val Loss: 0.6433, Val Acc: 95.75%\n",
            "Epoch: 6/100\n",
            "Train Loss: 0.6407, Train Acc: 93.90% | Val Loss: 0.6337, Val Acc: 96.00%\n",
            "Epoch: 7/100\n",
            "Train Loss: 0.6336, Train Acc: 94.25% | Val Loss: 0.6279, Val Acc: 96.50%\n",
            "Epoch: 8/100\n",
            "Train Loss: 0.6259, Train Acc: 95.00% | Val Loss: 0.6195, Val Acc: 96.75%\n",
            "Epoch: 9/100\n",
            "Train Loss: 0.6183, Train Acc: 96.20% | Val Loss: 0.6114, Val Acc: 96.75%\n",
            "Epoch: 10/100\n",
            "Train Loss: 0.6108, Train Acc: 96.20% | Val Loss: 0.6016, Val Acc: 96.75%\n",
            "Epoch: 11/100\n",
            "Train Loss: 0.6017, Train Acc: 96.85% | Val Loss: 0.5959, Val Acc: 96.75%\n",
            "Epoch: 12/100\n",
            "Train Loss: 0.5944, Train Acc: 96.40% | Val Loss: 0.5853, Val Acc: 96.75%\n",
            "Epoch: 13/100\n",
            "Train Loss: 0.5845, Train Acc: 96.60% | Val Loss: 0.5756, Val Acc: 97.50%\n",
            "Epoch: 14/100\n",
            "Train Loss: 0.5745, Train Acc: 97.10% | Val Loss: 0.5669, Val Acc: 97.75%\n",
            "Epoch: 15/100\n",
            "Train Loss: 0.5663, Train Acc: 96.80% | Val Loss: 0.5546, Val Acc: 97.50%\n",
            "Epoch: 16/100\n",
            "Train Loss: 0.5548, Train Acc: 97.70% | Val Loss: 0.5492, Val Acc: 97.25%\n",
            "Epoch: 17/100\n",
            "Train Loss: 0.5448, Train Acc: 97.15% | Val Loss: 0.5391, Val Acc: 97.50%\n",
            "Epoch: 18/100\n",
            "Train Loss: 0.5350, Train Acc: 97.15% | Val Loss: 0.5256, Val Acc: 97.75%\n",
            "Epoch: 19/100\n",
            "Train Loss: 0.5246, Train Acc: 97.10% | Val Loss: 0.5173, Val Acc: 97.25%\n",
            "Epoch: 20/100\n",
            "Train Loss: 0.5139, Train Acc: 97.20% | Val Loss: 0.4998, Val Acc: 98.00%\n",
            "Epoch: 21/100\n",
            "Train Loss: 0.5047, Train Acc: 96.95% | Val Loss: 0.4880, Val Acc: 98.25%\n",
            "Epoch: 22/100\n",
            "Train Loss: 0.4944, Train Acc: 97.25% | Val Loss: 0.4867, Val Acc: 98.50%\n",
            "Epoch: 23/100\n",
            "Train Loss: 0.4842, Train Acc: 97.25% | Val Loss: 0.4723, Val Acc: 98.00%\n",
            "Epoch: 24/100\n",
            "Train Loss: 0.4734, Train Acc: 96.95% | Val Loss: 0.4620, Val Acc: 97.75%\n",
            "Epoch: 25/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _after_fork at 0x7ddd1d68b600>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1663, in _after_fork\n",
            "    thread._reset_internal_locks(False)\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 917, in _reset_internal_locks\n",
            "    self._started._at_fork_reinit()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 573, in _at_fork_reinit\n",
            "    self._cond._at_fork_reinit()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 267, in _at_fork_reinit\n",
            "    def _at_fork_reinit(self):\n",
            "\n",
            "KeyboardInterrupt: \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-4f6f90890d69>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.00001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Test model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-d9b3db2d5367>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, num_epochs, lr)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         print(f\"Train Loss: {running_loss/len(train_loader):.4f}, Train Acc: {train_acc:.2f}% | \"\n",
            "\u001b[0;32m<ipython-input-2-d9b3db2d5367>\u001b[0m in \u001b[0;36mvalidate_model\u001b[0;34m(model, val_loader, criterion, device)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m             \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    482\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_worker_number_rationality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_MultiProcessingDataLoaderIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m   1106\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m             \u001b[0;31m# No certainty which module multiprocessing_context is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1108\u001b[0;31m             \u001b[0mindex_queue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultiprocessing_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQueue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[var-annotated]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1109\u001b[0m             \u001b[0;31m# Need to `cancel_join_thread` here!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m             \u001b[0;31m# See sections (2) and (3b) above.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/multiprocessing/context.py\u001b[0m in \u001b[0;36mQueue\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;34m'''Returns a queue object'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mqueues\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mQueue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mQueue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mJoinableQueue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/multiprocessing/queues.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, maxsize, ctx)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# For use by concurrent.futures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ignore_epipe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'win32'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/multiprocessing/queues.py\u001b[0m in \u001b[0;36m_reset\u001b[0;34m(self, after_fork)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_notempty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_at_fork_reinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_notempty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthreading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCondition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthreading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeque\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, lock)\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_waiters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deque\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_at_fork_reinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to print model weights as NumPy arrays\n",
        "def print_model_weights(model):\n",
        "    for name, param in model.named_parameters():\n",
        "        if param.requires_grad and ('conv1.weight' in name):\n",
        "            np_array = param.cpu().detach().numpy()  # Convert to NumPy\n",
        "            print(np_array.shape)\n",
        "            print(f\"{name} weights as NumPy array:\\n\")\n",
        "            for i in np_array:\n",
        "              print(i)\n",
        "\n",
        "# After training, print weights\n",
        "print_model_weights(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvJkCW7sKmcw",
        "outputId": "c8e9544b-39c0-41b0-ec5a-e755cedf6f1f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 3, 3, 3)\n",
            "conv1.weight weights as NumPy array:\n",
            "\n",
            "[[[ 0.  0. -0.]\n",
            "  [ 0. -0. -0.]\n",
            "  [-0.  0. -0.]]\n",
            "\n",
            " [[-0. -0.  0.]\n",
            "  [ 0.  0. -0.]\n",
            "  [ 0. -0. -0.]]\n",
            "\n",
            " [[ 0.  0.  0.]\n",
            "  [-0. -0.  0.]\n",
            "  [ 0.  0. -0.]]]\n",
            "[[[-0.12307724 -0.08977024  0.16669354]\n",
            "  [-0.09600206  0.1897963  -0.06423801]\n",
            "  [ 0.02577408  0.07815539 -0.06687439]]\n",
            "\n",
            " [[ 0.0320854   0.0860556   0.16490394]\n",
            "  [ 0.01227864 -0.13354412 -0.08475346]\n",
            "  [ 0.04780046  0.21088582  0.02029063]]\n",
            "\n",
            " [[-0.10095371  0.11851704 -0.17908937]\n",
            "  [-0.1878032  -0.22275762  0.03052068]\n",
            "  [-0.14742047 -0.08661371 -0.16748086]]]\n",
            "[[[ 0.12408992 -0.17044146  0.0790939 ]\n",
            "  [-0.18736403 -0.09220495 -0.07624567]\n",
            "  [ 0.12770003 -0.02788427 -0.21036267]]\n",
            "\n",
            " [[ 0.13417016  0.00252966  0.01043558]\n",
            "  [ 0.1579734  -0.07719019 -0.18018089]\n",
            "  [ 0.050235    0.00956193  0.09973624]]\n",
            "\n",
            " [[-0.18657917  0.07340908 -0.05518973]\n",
            "  [ 0.0400635   0.13163246  0.19825056]\n",
            "  [-0.07612858  0.15967353  0.11016011]]]\n",
            "[[[-0.20334475 -0.11002831 -0.05332335]\n",
            "  [-0.217691    0.11863945 -0.19000143]\n",
            "  [ 0.09993111 -0.00038127 -0.11732057]]\n",
            "\n",
            " [[ 0.08694841  0.02132185 -0.182883  ]\n",
            "  [-0.15833199  0.13745259 -0.01141209]\n",
            "  [ 0.11664563  0.02161178  0.01377401]]\n",
            "\n",
            " [[ 0.1662481   0.04543386 -0.00993959]\n",
            "  [-0.10743056 -0.01926812  0.13702537]\n",
            "  [ 0.20017076 -0.03144668 -0.10265215]]]\n",
            "[[[-0.213922   -0.14056076  0.12135313]\n",
            "  [ 0.08020371 -0.03550604 -0.14772178]\n",
            "  [-0.07206848  0.11161959  0.09433492]]\n",
            "\n",
            " [[ 0.05080475 -0.17478874  0.11272253]\n",
            "  [ 0.02058755  0.09919412  0.07085644]\n",
            "  [-0.12370178  0.11327438  0.08977655]]\n",
            "\n",
            " [[ 0.11428023 -0.18861534 -0.18146808]\n",
            "  [ 0.0064258   0.16665304 -0.01514488]\n",
            "  [ 0.17345676 -0.05850592 -0.11296508]]]\n",
            "[[[ 0.06697568 -0.11772346  0.05238551]\n",
            "  [-0.06262003  0.01833564 -0.06167289]\n",
            "  [ 0.1749894   0.11595151 -0.15508713]]\n",
            "\n",
            " [[ 0.0759275  -0.05414154  0.11644274]\n",
            "  [ 0.0294313  -0.17876916  0.14437771]\n",
            "  [ 0.1516174   0.04164144  0.15809436]]\n",
            "\n",
            " [[-0.16264932 -0.16482297 -0.06127699]\n",
            "  [-0.13214432 -0.01316662  0.05940094]\n",
            "  [-0.17564496  0.00773658 -0.18751246]]]\n",
            "[[[ 0.12221818  0.03541977 -0.03306051]\n",
            "  [ 0.0819079   0.14729893  0.10400103]\n",
            "  [-0.06982043 -0.01456118 -0.16338554]]\n",
            "\n",
            " [[-0.00065428 -0.15916574  0.14977053]\n",
            "  [-0.17673649 -0.03426923  0.17442328]\n",
            "  [-0.13314384 -0.05625917  0.1561656 ]]\n",
            "\n",
            " [[ 0.15511324  0.02450481 -0.1347708 ]\n",
            "  [-0.15932454  0.2021768   0.04247881]\n",
            "  [ 0.12396871  0.1842818   0.12114213]]]\n",
            "[[[ 0.06944262  0.02168384 -0.08266615]\n",
            "  [-0.04751206 -0.18181252  0.07419591]\n",
            "  [ 0.20813791  0.08608513  0.1638142 ]]\n",
            "\n",
            " [[ 0.12057991  0.11149707 -0.18533494]\n",
            "  [-0.16343436 -0.05866022 -0.01205351]\n",
            "  [ 0.13172047 -0.10193267 -0.02028856]]\n",
            "\n",
            " [[-0.10063725  0.02313891  0.11859234]\n",
            "  [ 0.04258255  0.13838676 -0.17639737]\n",
            "  [ 0.20052254 -0.14439753 -0.03967016]]]\n",
            "[[[ 0.01005205  0.0823123   0.14218473]\n",
            "  [ 0.10404164  0.02148647  0.05581261]\n",
            "  [-0.04183779 -0.1761453   0.03789693]]\n",
            "\n",
            " [[-0.14718208 -0.17557473  0.09253564]\n",
            "  [-0.11848281  0.0226823  -0.07662694]\n",
            "  [-0.03082448  0.00537037  0.04122484]]\n",
            "\n",
            " [[ 0.08216848  0.10693177  0.14026839]\n",
            "  [ 0.13965619 -0.16544819  0.13088384]\n",
            "  [-0.07466744  0.17350066 -0.02761005]]]\n",
            "[[[ 0.01401083  0.23507802 -0.0647427 ]\n",
            "  [ 0.02494056 -0.02830981 -0.04846398]\n",
            "  [-0.03848425 -0.04620515 -0.04935854]]\n",
            "\n",
            " [[-0.2375097  -0.1758314  -0.03673557]\n",
            "  [-0.11734082 -0.26012015 -0.2789139 ]\n",
            "  [-0.22060584  0.01669893  0.05661343]]\n",
            "\n",
            " [[-0.12965652  0.00094652  0.1196925 ]\n",
            "  [ 0.0759534  -0.04409066 -0.08144789]\n",
            "  [ 0.1686502  -0.1541299  -0.02944251]]]\n",
            "[[[ 0. -0.  0.]\n",
            "  [ 0. -0.  0.]\n",
            "  [-0. -0. -0.]]\n",
            "\n",
            " [[ 0. -0.  0.]\n",
            "  [ 0.  0.  0.]\n",
            "  [ 0.  0.  0.]]\n",
            "\n",
            " [[-0. -0. -0.]\n",
            "  [ 0. -0. -0.]\n",
            "  [-0. -0.  0.]]]\n",
            "[[[-0. -0.  0.]\n",
            "  [ 0.  0.  0.]\n",
            "  [ 0.  0.  0.]]\n",
            "\n",
            " [[-0. -0.  0.]\n",
            "  [ 0. -0. -0.]\n",
            "  [ 0.  0.  0.]]\n",
            "\n",
            " [[-0.  0.  0.]\n",
            "  [-0. -0. -0.]\n",
            "  [ 0.  0.  0.]]]\n",
            "[[[-0. -0. -0.]\n",
            "  [ 0.  0.  0.]\n",
            "  [-0.  0. -0.]]\n",
            "\n",
            " [[ 0.  0. -0.]\n",
            "  [ 0. -0.  0.]\n",
            "  [-0.  0. -0.]]\n",
            "\n",
            " [[-0.  0.  0.]\n",
            "  [-0.  0.  0.]\n",
            "  [ 0.  0.  0.]]]\n",
            "[[[-0.  0. -0.]\n",
            "  [ 0.  0.  0.]\n",
            "  [-0.  0.  0.]]\n",
            "\n",
            " [[ 0.  0.  0.]\n",
            "  [ 0. -0.  0.]\n",
            "  [ 0. -0. -0.]]\n",
            "\n",
            " [[ 0.  0.  0.]\n",
            "  [ 0. -0. -0.]\n",
            "  [ 0.  0. -0.]]]\n",
            "[[[-0. -0.  0.]\n",
            "  [-0. -0. -0.]\n",
            "  [ 0.  0. -0.]]\n",
            "\n",
            " [[ 0.  0.  0.]\n",
            "  [-0. -0.  0.]\n",
            "  [-0. -0. -0.]]\n",
            "\n",
            " [[-0.  0. -0.]\n",
            "  [ 0. -0.  0.]\n",
            "  [-0. -0. -0.]]]\n",
            "[[[-0.  0. -0.]\n",
            "  [-0.  0.  0.]\n",
            "  [-0. -0.  0.]]\n",
            "\n",
            " [[-0. -0. -0.]\n",
            "  [-0. -0.  0.]\n",
            "  [-0.  0. -0.]]\n",
            "\n",
            " [[-0.  0.  0.]\n",
            "  [-0. -0.  0.]\n",
            "  [-0. -0. -0.]]]\n",
            "[[[ 0. -0.  0.]\n",
            "  [-0.  0.  0.]\n",
            "  [-0. -0. -0.]]\n",
            "\n",
            " [[ 0. -0. -0.]\n",
            "  [-0. -0.  0.]\n",
            "  [ 0. -0. -0.]]\n",
            "\n",
            " [[-0. -0.  0.]\n",
            "  [-0.  0.  0.]\n",
            "  [-0.  0. -0.]]]\n",
            "[[[-0. -0. -0.]\n",
            "  [-0.  0.  0.]\n",
            "  [-0. -0. -0.]]\n",
            "\n",
            " [[ 0.  0.  0.]\n",
            "  [-0.  0.  0.]\n",
            "  [ 0.  0. -0.]]\n",
            "\n",
            " [[-0. -0. -0.]\n",
            "  [-0. -0.  0.]\n",
            "  [-0. -0.  0.]]]\n",
            "[[[ 0.  0. -0.]\n",
            "  [-0. -0.  0.]\n",
            "  [ 0. -0. -0.]]\n",
            "\n",
            " [[-0. -0.  0.]\n",
            "  [-0. -0.  0.]\n",
            "  [-0.  0.  0.]]\n",
            "\n",
            " [[ 0. -0. -0.]\n",
            "  [-0. -0.  0.]\n",
            "  [-0. -0.  0.]]]\n",
            "[[[ 0.  0. -0.]\n",
            "  [ 0.  0. -0.]\n",
            "  [-0. -0.  0.]]\n",
            "\n",
            " [[-0. -0.  0.]\n",
            "  [-0. -0. -0.]\n",
            "  [ 0.  0. -0.]]\n",
            "\n",
            " [[ 0.  0. -0.]\n",
            "  [ 0. -0.  0.]\n",
            "  [ 0. -0. -0.]]]\n",
            "[[[ 0. -0.  0.]\n",
            "  [ 0.  0.  0.]\n",
            "  [ 0. -0.  0.]]\n",
            "\n",
            " [[-0. -0. -0.]\n",
            "  [-0.  0. -0.]\n",
            "  [ 0.  0. -0.]]\n",
            "\n",
            " [[ 0.  0. -0.]\n",
            "  [-0.  0.  0.]\n",
            "  [ 0. -0.  0.]]]\n",
            "[[[ 0. -0.  0.]\n",
            "  [-0. -0.  0.]\n",
            "  [ 0. -0. -0.]]\n",
            "\n",
            " [[ 0.  0.  0.]\n",
            "  [-0. -0. -0.]\n",
            "  [ 0. -0. -0.]]\n",
            "\n",
            " [[ 0.  0. -0.]\n",
            "  [ 0.  0. -0.]\n",
            "  [ 0.  0. -0.]]]\n",
            "[[[-0. -0. -0.]\n",
            "  [-0.  0.  0.]\n",
            "  [ 0.  0. -0.]]\n",
            "\n",
            " [[ 0.  0. -0.]\n",
            "  [ 0. -0.  0.]\n",
            "  [ 0. -0. -0.]]\n",
            "\n",
            " [[ 0.  0.  0.]\n",
            "  [ 0. -0. -0.]\n",
            "  [ 0.  0.  0.]]]\n",
            "[[[-0. -0. -0.]\n",
            "  [ 0.  0.  0.]\n",
            "  [ 0.  0.  0.]]\n",
            "\n",
            " [[-0.  0. -0.]\n",
            "  [-0. -0. -0.]\n",
            "  [ 0. -0. -0.]]\n",
            "\n",
            " [[-0.  0.  0.]\n",
            "  [-0. -0.  0.]\n",
            "  [-0.  0.  0.]]]\n",
            "[[[ 0. -0.  0.]\n",
            "  [-0. -0.  0.]\n",
            "  [-0. -0.  0.]]\n",
            "\n",
            " [[-0.  0.  0.]\n",
            "  [ 0. -0. -0.]\n",
            "  [ 0.  0.  0.]]\n",
            "\n",
            " [[-0.  0. -0.]\n",
            "  [ 0.  0. -0.]\n",
            "  [ 0. -0. -0.]]]\n",
            "[[[-0.  0.  0.]\n",
            "  [-0. -0. -0.]\n",
            "  [-0. -0.  0.]]\n",
            "\n",
            " [[ 0.  0.  0.]\n",
            "  [-0. -0.  0.]\n",
            "  [-0.  0. -0.]]\n",
            "\n",
            " [[-0.  0.  0.]\n",
            "  [-0.  0. -0.]\n",
            "  [ 0. -0. -0.]]]\n",
            "[[[ 0. -0.  0.]\n",
            "  [ 0.  0.  0.]\n",
            "  [ 0. -0.  0.]]\n",
            "\n",
            " [[ 0.  0.  0.]\n",
            "  [ 0.  0. -0.]\n",
            "  [-0. -0. -0.]]\n",
            "\n",
            " [[-0.  0.  0.]\n",
            "  [ 0. -0. -0.]\n",
            "  [-0.  0.  0.]]]\n",
            "[[[-0. -0.  0.]\n",
            "  [-0.  0.  0.]\n",
            "  [ 0. -0. -0.]]\n",
            "\n",
            " [[ 0. -0.  0.]\n",
            "  [-0.  0.  0.]\n",
            "  [ 0.  0. -0.]]\n",
            "\n",
            " [[-0.  0.  0.]\n",
            "  [-0. -0. -0.]\n",
            "  [-0.  0.  0.]]]\n",
            "[[[-0.  0.  0.]\n",
            "  [ 0.  0.  0.]\n",
            "  [-0.  0. -0.]]\n",
            "\n",
            " [[-0. -0.  0.]\n",
            "  [-0.  0.  0.]\n",
            "  [-0. -0. -0.]]\n",
            "\n",
            " [[-0.  0. -0.]\n",
            "  [ 0. -0. -0.]\n",
            "  [ 0.  0.  0.]]]\n",
            "[[[-0. -0. -0.]\n",
            "  [-0. -0. -0.]\n",
            "  [ 0. -0.  0.]]\n",
            "\n",
            " [[ 0.  0.  0.]\n",
            "  [-0. -0.  0.]\n",
            "  [ 0.  0. -0.]]\n",
            "\n",
            " [[ 0.  0. -0.]\n",
            "  [-0.  0.  0.]\n",
            "  [ 0. -0.  0.]]]\n",
            "[[[ 0.  0.  0.]\n",
            "  [-0. -0. -0.]\n",
            "  [ 0. -0.  0.]]\n",
            "\n",
            " [[ 0.  0. -0.]\n",
            "  [-0. -0. -0.]\n",
            "  [ 0. -0. -0.]]\n",
            "\n",
            " [[ 0. -0. -0.]\n",
            "  [-0. -0. -0.]\n",
            "  [ 0. -0. -0.]]]\n",
            "[[[-0.  0. -0.]\n",
            "  [-0. -0. -0.]\n",
            "  [ 0. -0. -0.]]\n",
            "\n",
            " [[-0. -0. -0.]\n",
            "  [-0.  0. -0.]\n",
            "  [-0. -0.  0.]]\n",
            "\n",
            " [[ 0.  0.  0.]\n",
            "  [-0. -0. -0.]\n",
            "  [ 0. -0. -0.]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UmspIAZnYyZM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}